{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 18:59:00.092103: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-14 18:59:00.276788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-14 18:59:00.277848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-14 18:59:01.580880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import base64\n",
    "import cv2\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = VGG16(weights='imagenet')\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "    def extract(self, img):\n",
    "        \"\"\"\n",
    "        Extract a deep feature from an input image\n",
    "        Args:\n",
    "            img: from PIL.Image.open(path) or tensorflow.keras.preprocessing.image.load_img(path)\n",
    "\n",
    "        Returns:\n",
    "            feature (np.ndarray): deep feature with the shape=(4096, )\n",
    "        \"\"\"\n",
    "        img = img.resize((224, 224))  # VGG must take a 224x224 img as an input\n",
    "        img = img.convert('RGB')  # Make sure img is color\n",
    "        x = image.img_to_array(img)  # To np.array. Height x Width x Channel. dtype=float32\n",
    "        x = np.expand_dims(x, axis=0)  # (H, W, C)->(1, H, W, C), where the first elem is the number of img\n",
    "        x = preprocess_input(x)  # Subtracting avg values for each pixel\n",
    "        feature = self.model.predict(x)[0]  # (1, 4096) -> (4096, )\n",
    "        return feature / np.linalg.norm(feature)  # Normalize\n",
    "    \n",
    "    def get_from_link(self, img_link: str):\n",
    "        image = io.imread(img_link)\n",
    "        return self._extract(image)\n",
    "\n",
    "    def get_from_image(self, img):\n",
    "        image_bytes=base64.b64decode(img)\n",
    "        image_np=np.frombuffer(image_bytes,dtype=np.uint8)\n",
    "        img=cv2.imdecode(image_np,cv2.IMREAD_COLOR)\n",
    "        return self._extract(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=Image.open(\"infra/data/mirflickr25k/mirflickr/im3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 18:59:20.319378: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-10-14 18:59:20.606549: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-10-14 18:59:20.747333: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-10-14 18:59:20.853864: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory.\n",
      "2024-10-14 18:59:21.081634: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-10-14 18:59:21.125872: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 356ms/step\n"
     ]
    }
   ],
   "source": [
    "fe=FeatureExtractor()\n",
    "img=fe.extract(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.0524362 0.        ... 0.        0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Backend.backend_config as config\n",
    "from elasticsearch import Elasticsearch\n",
    "from Backend.feature_extractor import FeatureExtractor\n",
    "from PIL import Image\n",
    "import io\n",
    "import  base64\n",
    "#Elasticsearch Client\n",
    "client = Elasticsearch(\n",
    "    [config.elastic_url], basic_auth=(config.elastic_usr, config.elastic_pass)\n",
    ")\n",
    "# Import FeatureExtractor Class\n",
    "fe = FeatureExtractor()\n",
    "\n",
    "\n",
    "def get_results_search_by_image(img, show_result):\n",
    "    # DÃ©coder l'image base64 en bytes\n",
    "    \n",
    "    img = base64.b64decode(img)\n",
    "    img = Image.open(io.BytesIO(img))\n",
    "    # Afficher l'image\n",
    "    img.show()\n",
    "    image_feature = fe.get_from_image(img)\n",
    "    body = {\n",
    "        \"knn\": {\n",
    "            \"field\": \"FeatureVector\",\n",
    "            \"query_vector\": image_feature,\n",
    "            \"k\": 10,\n",
    "            \"num_candidates\": 50,\n",
    "        },\n",
    "        \"_source\": [\"OriginalURL\"],\n",
    "    }\n",
    "    results = client.search(\n",
    "        index=config.index_name, body=body, size=show_result\n",
    "    )\n",
    "    return {\"resulttype\": results}\n",
    "\n",
    "#======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
